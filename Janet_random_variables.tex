\section{Binomial and Hypergeometric}\smallskip \hrule height 2pt \smallskip
Note: this is for objects that are indistinguishable.  You can distinguish a red fish from a blue fish but you can't tell whether a red fish's name is "Mary" or "Gary". 
\hfill \\

\subsection{Binomial distribution/"probability"}
	\begin{description}
		
		\item[Binomial Distribution] ("Probability" in 10/12 lecture). A series of \textbf{independent trials}, each resulting in one of \textbf{two} possible outcomes, "success", or "failure".  So yes replacement if it keeps trials independent, and can't have three possible outcomes. 
			\[ P(k \mbox \ successes) = {{n}\choose{k}}p^k(1-p)^k \mbox{, for \ } k = 0, 1, \dots, n \]
		Note this is the number of ways of getting $k$ indistinguishable objects in n tries.  Then you multiply by the probability, $p^k$, of getting that number $k$, and the probability $(1-p)^k$ of getting the rest.  $P(\mbox{2 heads out of three for a coin that gives heads 3/4 of the time}) = (3)*(0.75^2)*(0.25^1)$ \hfill \\
		\hfill \\
	\end{description}

\subsection{Hypergeometric Distribution}
	\begin{description}
		\item[Hypergeometric Distribution]  For \textbf{no replacement}.  Draw $n$ chips from an urn that has $r$ red chips, $w$ white chips, and $r + w = N$.   $n$ is the total number of chips you will draw; $k/n$ will be the fraction you draw that are red. Draw chips without replacement.  Note k must be < r or the problem doesn't make sense and something like ${{r} \choose {k}} = {{1} \choose {5}} = ?!?!$ can happen.  
			\[ P(\mbox{k red chips chosen}) = \frac{ {{r} \choose {k}} {{w} \choose {n-k}} }{{{N}\choose{k}}} \] % \frac{{{r}\choose{k}}{w \chose {n-k}}}{N \chose k} \]
			\[ \frac{\mbox{(ways to draw \ k red from r)}*\mbox{(ways to draw n-k non-red from r)}}{\mbox{total number of combinations of chips you can draw}} \] \hfill \\
		Note: this is the same as	{\tiny pg 111}
		\[ = \frac{ {{n} \choose {k}} ({{_r}P_{k}}) ({{_w}P_{n-k}}) }{{{_N}P_n}} \] 
			\hfill \\
		Note that if you sample a very small fraction of the fish pond you will recover the binomial distribution (because replacement vs. no replacement isn't so important). \hfill \\
		\hfill \\
		Say you have $1, 2, 3, \dots, t$ types of objects with numbers $n_1, n_2, \dots, n_t$ in an urn.
		If you want to chose $k_1$ objects of  type 1, $k_2$ objects of  type 2, $\dots$ $k_t$ objects of  type $t$.\
		Then the number of objects is $N = n_1 + n_2 + \dots + n_t$, the number you are selecting is $n = k_1+ k_2 + \dots + k_t$, and  the formula is   {\tiny q 3.2.35, pg 118}
		\[  \frac{ {{n_1}\choose{k_1}} {{n_2}\choose{k_2}} \dots {{n_t}\choose{k_t}} }{ {{N}\choose{n}} }  \]
		This is different than the formula I derived.  I was multiplying the probabilities separately, and updating N each time.  Is this an overestimation? 		
	\end{description}
	
\section{Random Variables} 

\begin{center}
\begin{tabular}{ c c c c c }
 \textbf{R.Var.} & \textbf{pdf} & \textbf{cdf} &   \\ 
 	discrete &   pmf (m $=$ mass) & cdf \\
	continuous & pdf (d $=$ density) & cdf
 \end{tabular}
\end{center}
\hfill \\
A probability mass function (pmf) is a function that gives the probability that a discrete random variable is exactly equal to some value.
A probability mass function differs from a probability density function (pdf) in that the latter is associated with continuous rather than discrete random variables; the values of the latter are not probabilities as such: a pdf must be integrated over an interval to yield a probability.
%\begin{center}
%\begin{tabular}{ c c c c c }
 %\textbf{R.Var.} & \textbf{density} & \textbf{cumulative} &   \\ 
 %	discrete & pmf  or pdf & cdf \\
%	continuous & pdf & cdf
 %\end{tabular}
%\end{center}
%\hfill \\


\subsection{Discrete probability function}
Suppose S is a finite or countably infinite sample space.  Let $p$ be a real-valued function defined for each element of $S$ such that: {\tiny pg 119} \hfill \\
(a)  \[ 0 < p(s) \mbox{ for each \ } s \in S  \] 
(b)  \[  \sum\limits_{s \in S} p(s) = 1 \]
Then $p$ is said to be a \textit{discrete probability function} \hfill \\
\hfill \\
Once $p(s)$ is defined for all $s$, then you can say the probability of any event $A$ is the sum of the probabilities of the outcomes comprising $A$: 
\[  P(A) = \sum\limits_{s \in S} p(s) \]
This function satisfies the probability axioms of Section 2.3.   \hfill \\

Note: you can still have an infinite number of outcomes in the sample space, as long as the probability of all outcomes sums to one.  E.g. probability of getting heads on an odd numbered coin toss has an infinite number of events but if you sum the two sums (got it on odd, got it on even), you get a sum of 1.  {\tiny pg 120}

\subsection{Discrete random variable}
3 Lecture Axioms: {\tiny 10/14}:   $\Omega \rightarrow {\cal X} \subseteq $ R   \hfill \\  
(The sample space is ${\cal X}$, which is real.)  Pg 119 has a similar set of facts, that are presented a little differently. 
 \hfill \\  
	\[  P(X=x) \geq 0 \mbox{, \ \  }  P(X=x) > 0  \mbox{ if } x \in {\cal X}  \]
%(book version (pg 119)): $ 0 \leq p(s)$ for each $s \in S$. ($S$ is a finite or countably infinite sample space. P is a real -valued function defined over eac element of S) 
	\[  P(\Omega) = 1 \mbox{, so \ }  \sum\limits_{x \in \cal X} P(x= {\cal X}) = 1\]
$E_1$, $E_2$, $\dots$, $E_k$ are disjoint (non-overlapping). 
	\[ P(E_1 \cup E_2 \cup \dots \cup E_k) =  \sum\limits_{i=1} P(E_i) \mbox{;} P(x \in B) = \sum\limits_{{\cal X} \in B} P(x = {\cal X}) \]
We have done this.  E.g. P(X is 2, 3, or 4) $= P(X=2)$ + $P(X=3)$ + $P(X=4)$
	%\[  E_1, E_2, \dots, E_k \mbox{ are disjoint (non-ovaerlapping).} P(E_1 \cup E_2 \cup \dots \cup E_k) =  \sum\limits_{i=1} P(E_i) \]
	%\[  P(\Omega) = 1, so  \sum\limits_{i=1}^k P(E_i)  \mbox{ if } x \in {\cal X} \]
	
     \hfill \\  
  \hfill \\  
A function whose domain is a sample space $S$ and whose values form a finite or countably infinite set of real numbers is called a \textbf{discrete random variable}.  We denote random variables by uppercase letters, often X or Y.  {\tiny page 123}  \hfill \\
Example: sum of the values of two die faces.  E.g. value of die 1 is $X_1$, value of die 2 is $X_2$, value of sum is $X = X_1 + X_2$    \hfill \\  
  \hfill \\  
  
\textbf{The Probability Density Function}.  Associated with every discrete random variable X is a \textit{probability density function} (or \textit{pdf}), denoted $p_x(k)$ where 
	\[  p_X(k) = P({s \in S \mid X(s) = k})  \]
That's often written as $ p_X(k) = P(X = k) $.  \hfill \\  
Note: the binomial distribution is such an example:   (So is hypergeometric.) 
	\[  p_x(k) = P(k \mbox \ successes) = {{n}\choose{k}}p^k(1-p)^k \mbox{, for \ } k = 0, 1, \dots, n \]

\subsection{Cumulative Distribution Function} \textbf{(Discrete)}
You might want $P(x \leq X \leq t) = P(X \leq t) - P(X \leq s - 1)$  {\tiny pg 127}  \hfill \\  
\textbf{Cumulative distribution function}:  Let $X$ be a discrete random variable.  For any real number $t$, the probability that $X$ takes on a value $\leq t$ is the \textit{cumulative distribution} (cdf) of $X$ [written $F_X(t)$].
	\[ F_X(t) = P({s \ in S \mid X(s) \leq t}) \]
or more simply 
	\[  F_X(t) = P(X \leq t)  \]
	
\subsection{Continuous random variables}
A probability function $P$ on a set of real numbers $S$ is called \textbf{continuous} if there exists a function $f(t)$ such that for any closed interval $[a, b] \subset S$, $P([a, b]) = \int_{a}^{b} f(t)dt$. \hfill \\  
Kind of obvious, but all values of the function must be more than zero.  \hfill \\  

\subsection{Continuous probability density functions}
{\tiny (pg 135)} Let $Y$ be a function from a sample space $S$ to the real-numbers (takes values of real numbers; put in something and you get out a real number).  The function $Y$ is called a \textit{continuous random variable} if there exists a function $f_Y(y)$ such that for any real numbers $a$ and $b$ with $a < b$:
	\[  P(a \leq Y \leq b) = \int_{a}^{b} f_Y(y)dy \]
The function $f_Y(y)$ is the \textbf{\textit{probability density function (pdf)}} for $Y$.  Think of "density" as corresponding to how much height there is over the x-axis when you plot $f_Y(y)$ versus $y$.  \hfill \\

\hfill \\ 
\textbf{The value of $f$ can be greater than 1}.  {\tiny See 10/28 lecture.}   If $f_X(x) = c$ for $ 0 \leq x \leq 1/2$ then the area has to $= 1$ so $c = 2$.  So $p_X(x) = 2$. 

\subsection{Continuous cumulative distribution functions}
As in the discrete case, the \textit{cumulative distribution function (cdf)} is defined by $F_Y(y) = P(Y \leq y)$: {\tiny (pg 136)}
	\[  F_Y(y) = P(Y \leq y) = \int_{- \inf}^{y} f_Y(t)dt \]
Also written as  {\tiny (Definition 3.4.3: pg 137)}
	\[  F_Y(y) = \int_{- \inf}^{y} f_Y(r)dr = P({s \in S \mid Y(s) \leq y}) = P(Y < y) \]
The cdf in this case is an integral of $f_Y(y)$.  Note that now we have $f_Y(t)$ or $f_Y(r)$, not $f_Y(y)$.  We are still integrating over the x-axis ($y$) but we can't have $y$ in $dy$ and in the integration limits.   \hfill \\  
Also note the derivative of the cdf is the pdf:
	\[  \frac{d}{dy}F_Y(y) = f_Y(y) \]
	
\subsection{Expected Values}
Let $X$ be a discrete random variable with probability function $p_X(k)$.  The \textit{expected value} of $X$ is denoted E(X) (or sometimes $\mu$ or $\mu x$ and is given by: {\tiny pg 140}   \hfill \\  
\textbf{Discrete:}
	\[  E(X) = \mu = \mu x = \sum\limits_{\mbox{all } k} k*p_X(k)  \]
\textbf{Random:}	  \hfill \\  
	\[  E(Y) = \mu = \mu y = \int_{- \inf}^{\inf} y*f(y)dy  \]
\textbf{binomial:} {\tiny pg 141, ~10/16 TA lecture} 	  \hfill \\
	\[ E(X) = np =  \sum\limits_{k=0}^{n} k \cdot p_X(k) = \sum\limits_{k=0}^{n}k \cdot {{n}\choose{k}}p^k(1-p)^k \]  
\textbf{hypergeometric}: for selecting $n$ balls from $r$ red balls and $w$ white balls{\tiny pg 143, ~10/16 TA lecture}  \hfill \\  
	\[ E(X) = \frac{rn}{r+w} \]
turns out the same if you substitute the proportion of red balls:
	\[ E(X) = n \cdot p \mbox{ for } p= \frac{r}{r+w} \]
\hfill \\  	

\subsection{The median}
If $X$ is a discrete random variable, the median, $m$, is that point for which $P(X < m) = P(X>m)$.  In the event that $P(X \leq m) = 0.5$ and $P(X \geq m')$, the median is defined to be the arithmetic average, $(m + m')/2$.  \hfill \\
If $Y$ is a continuous random variable, its median is the solution to the integral equation $\int_{- \inf}^{m} f(y)dy = 0.5$  \hfill \\
If a random variable's pdf is symmetric, both $\mu$ and $m$ will be equal.  

\subsection{Expected values for functions of random variables}
{\tiny (pg 150; Lecture 10/14)}  Suppose $X$ is a discrete random variable with pdf $p_X(k)$.  Let $g(X)$ be a function of $X$.  Then the expected value of the random variable $g(X)$ is given by: \hfill \\
	\[ E[g(X)] = \sum\limits_{\mbox{all k}} g(k) \cdot p_X(k) \]
Provided that $\sum\limits_{\mbox{all k}} | g(k)| \cdot p_X(k) < \inf$
\hfill \\
\hfill \\
If $Y$ is a discrete random variable with pdf $f_Y(y)$, and if $g(Y)$ is a continuous function, then the expected value of the random variable $g(Y)$ is: \hfill \\
	\[ E[g(Y)] = \sum\limits_{- \inf}^{\inf} g(y) \cdot f_Y(y)dy \]
Provided that $E[g(Y)] = \sum\limits_{\inf}^{\inf} | g(y)| \cdot f_Y(y)dy < \inf$  \hfill \\
\hfill \\

These two definitions highlight the difference in nomenclature.  See page 127 for definition of discrete cdf.  See page 135 for definition of continuous cdf 
\begin{center}
\begin{tabular}{ c c c c c }
 \textbf{R.Var.} & \textbf{x-axis} & \textbf{pdf notation} & \textbf{cdf notation}   \\ 
 $\mbox{\tiny discrete  } X$     & $k$ & $p_X(k)  \mbox{ \tiny or }  P(X=k) $ & $F_X(k) \mbox{ \tiny or } P(X \leq k)  $  \\  
$\mbox{\tiny continuous  } Y$ & $y$ & $f_Y(y)$                                          & $F_Y(y) \mbox{ \tiny or } P(Y \leq y)  $ 
\end{tabular}
\end{center}
\hfill \\


 \begin{center}
\begin{tabular}{ c c c c c }
 \textbf{R.Var.} & \textbf{pdf} & \textbf{cdf}  \\ 
 {discrete  } $X$    & $ p_X(x) = P(X=x)$ & $F_X(x) =  \sum\limits_{z \leq x}p_X(z)$  \\  
 {continuous  } $Y$ & $p_X(x) = 0$ {\tiny (at one point)}  & $F_Y(y) = \int_{-\infty}^{y}f_Y(y)$ \\  
\end{tabular}
\end{center}
\hfill \\
 
\textbf{NOTE:}  When we start talking about transforms of random variables, you can get $P$ that isn't CDF.  E.g. if $Y = X^3$ then the $P$s in $P(Y = y) = P(X^3 = y) = P(X = y^{1/3}) $ are probability, not cdf.  Note that there is no subscript in this case.  But that it looks rather like $P(X=k)$ in table above.   % $P(X) \mbox{ \tiny or } P(X = y)$

\hfill \\
Say your random variable is the number on a die face.  Say your function of that random variable is the square of that number.  If you want the expectation of the square, you can sum the products of the squares with the probabilities of the random variable values.  \hfill \\
\hfill \\
\textbf{Theorem} {\tiny (10/14 Lecture \& similar on pg 150)}:  \hfill \\
let $Y = g(X)$.  Since:
	\begin{align*}
		\mathbb{E} (Y) &=  \sum\limits_{y} yP(Y=y)   \\
			& = \sum\limits_{y} y \sum\limits_{x:g(x)=y} P(X = {\cal X})  \\
			& \mbox{note: above is a sum over the $y$ values,} \\ 
			& \mbox{and a sum over the $x$s that can give those y values.} \\
			& \mbox{There can be multiple $x$s that give a particular $y$.} \\
			& = \sum\limits_{y} \sum\limits_{x:g(x)=y} g(x)P(X=x) \\
			& \mbox{Drop $y$ sum b/c now everything is in terms of $x$} \\
			& \mbox{You are summing over all the events in a set that }   \\
			& \mbox{are indexed by y.  But when you take the sum over y, }  \\
			& \mbox{you say let's sum over all the different outcomes. } \\
			& = \sum\limits_{x \in {\cal X}} g(x)P(X=x) = \sum\limits_{x \in {\cal X}} g(x)P({\cal X}) \\ 
			& \mbox{This is a sum over all the $x$s in the whole set of outcomes (${\cal X}$)} 
	\end{align*} 
Note that this works for $g(Y) = Y^2$.  $E(Y^2) =  \int_{-\inf}^{\inf} Y^2 \cdot f_Y(y)dy  $.  {\tiny 10/21 review lecture}  \hfill \\
Loop over all the values the random variable takes (all $x$s in ${\cal X}$), and sum (probability of that $x$)*(the function applied to that $x$).  \hfill \\
 \hfill \\
 
\textbf{Addition of functions of random variables} 
{ \tiny (10/14 lecture)}
	\begin{align*}
		\mathbb{E} (g_1(x) + g_2(x)) &=   \sum\limits_{x \in {\cal X}} (g_1(x) + g_2(x))p(x) \\
			&= \sum\limits_{x \in {\cal X}} g_1(x)p(x) + \sum\limits_{x \in {\cal X}} g_2(x)p(x) \\
			&=\mathbb{E}  (g_1(x)) + \mathbb{E} (g_2(x)) \\
	\end{align*} 
Example $\mathbb{E}  (a(x) + b)$:
	\begin{align*}
		\mathbb{E} (a(x) + b) &=  \mathbb{E}  (a(x)) + \mathbb{E} (b) \\
			& = a\mathbb{E} (x) + b
	\end{align*} 
Example $\mathbb{E}  (x(x-1))$:
	\begin{align*}
		\mathbb{E} (x(x-1)) &= \mathbb{E} (x^1 - x)) \\
			& =  \mathbb{E}  (x^2) - \mathbb{E} (x)    \\
			& \mbox{this might be easier to evaluate}
	\end{align*} 
	
\section{Joint Density}

\textbf{Independence of random variables}.  {\tiny (page 175)} \hfill \\
$f_{X_1, X_2 , \dots, X_n}(x_1, x_2 , \dots, x_n) = g_1(x_1) g_2(x_2) \dots g_n(x_n)$. \hfill \\
\hfill \\
Example: if $X_1$, $X_2$, and $X_3$ are independent random variables each with pdf $f_{X_i}(x_i) = 4x_i^3$. 
Then $f_{X_1, X_2, X_3}(x_1, x_2, x_3) = (4x_1^3)(4x_2^3)(4x_3^3) = 4^3 x_1^3 x_2^3 4x_3^3$

\hfill \\

\textbf{memoryless property}.  You are waiting for a phone call.  The probability of the phone ringing in the next minute is constant and doesn't depend on how long you have been waiting.  More formally: X = phone call time (?)   \hfill \\
$P(X \geq s + t \mid x \geq s) = P(x \geq t) $ \hfill \\
$ $  \hfill \\

\textbf{Combining random variables}
If they are independent, you can multiply the independent distributions. 


Example from 10/26 TA review lecture: 
Say you have 50 random variables that are unform on $[0, 1]$.  $f_X1 = f_X2 = ... f_X50$.
The cdf is $F_X(x) = \{0 \mbox{ if } x < 0, x \mbox{ if } x \in [0, 1], 1 \mbox{ if } x > 1\}$.
Define $Y \equiv \mbox{max}(X_i)$.  Since they are independent, we know 
\begin{align*}
	P(Y \leq y) &= P(X_1 \leq y \mbox{ and } X_2 \leq y \mbox{ and }\dots \mbox{ and } X_{50} \leq y) \\
			& \mbox{\tiny independence allows multipication} \\
			&= P(X_1 \leq y) \cdot P(X_2 \leq y) \cdot \dots \cdot P(X_{50} \leq y) \\
			&= F_{X_1}(y) \dots F_{X_{50}}(y) =  y^{50} \\
		P(Y \leq y) &= y^{50} 
\end{align*}
{\tiny differentiate to convert from } $F_Y$ to $f_Y$:  $f_Y(y)=50y^{49}$
			
\section{Transforming/Combining Random Variables}
\subsection{Location/Scale}
\textbf{$Y = X + b$:} 
\begin{align*}
	F_Y(y) &= P(Y \leq y) \\
			&= P(X \leq y-b)  \\
			&= F_X(y - b)  \\
			& \mbox{differentiate} \\
	      \mathbf{f_Y(y)} & \mathbf{= f_X(y-b)}
\end{align*}

\subsection{Scaling Variables}
\textbf{$Y = aX $}: and $a > 0$. 
\begin{align*}
	F_Y(y) &= P(Y \leq y) \\
			&= P(aX \leq y)  \\
			&= P(X \leq y/a)  \\
			&= F_X(y/a)  \\
			& \mbox{differentiate} \\
		\mathbf{f_Y(y)} & \mathbf{= (1/a) \cdot f_X(y/a)}
\end{align*}

\subsection{Location and Scale}
\textbf{$Y = aX + b $}: (and $a > 0$). 
\begin{align*}
	F_Y(y) &= P(Y \leq y) \\
			&= P(aX + b \leq y)  \\
			&= P(X \leq (y-b)/a)  \\
			&= F_X((y-b)/a)  \\
			& \mbox{differentiate} \\
		\mathbf{f_Y(y)} & \mathbf{= (1/a) \cdot f_X((y-b)/a)}
\end{align*}

\subsection{Tricks for adding and multiplying random variables}

\textbf{example: add two variables}.  X and Y are uniform on $[0,1]$.  Find pdf of $Z = X + Y$.  Note that your range for Z is [0, 2].  Expect lots of probability around $Z = 1$, and zero at $Z = 0$ and $Z = 1$ 
\begin{align*}
	F_Z(z) &= P(Z \leq z) = P(X + Y \leq z) \\
	& \mbox{\tiny use conditional probability \& independence of X \& Y} \\
	&= \int_{- \infty}^{\infty} P(X + Y \leq z \mid X = x) \cdot f_X(x)dx
\end{align*}


